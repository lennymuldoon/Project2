{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "#importing backend from keras for precision\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is my own Customized layer that I am adding to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "myLayer = tf.keras.layers.Lambda(lambda x: (x*1.0000001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myMetric(y_true, y_pred):\n",
    "    y_pred_binary = tf.round(y_pred)\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(y_true, y_pred_binary), tf.float32))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2.1: I will now add more layers which will be the custom layer I created above. And I will "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_22 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_140 (Dense)           (None, 300)               235500    \n",
      "                                                                 \n",
      " batch_normalization_22 (Ba  (None, 300)               1200      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_141 (Dense)           (None, 250)               75250     \n",
      "                                                                 \n",
      " dense_142 (Dense)           (None, 200)               50200     \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_143 (Dense)           (None, 150)               30150     \n",
      "                                                                 \n",
      " lambda_4 (Lambda)           multiple                  0         \n",
      "                                                                 \n",
      " dense_144 (Dense)           (None, 50)                7550      \n",
      "                                                                 \n",
      " dense_145 (Dense)           (None, 10)                510       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 400360 (1.53 MB)\n",
      "Trainable params: 399760 (1.52 MB)\n",
      "Non-trainable params: 600 (2.34 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.6439 - accuracy: 0.7754 - myMetric: 24153578.0000 - val_loss: 0.4054 - val_accuracy: 0.8547 - val_myMetric: 1.3694\n",
      "Epoch 2/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4278 - accuracy: 0.8458 - myMetric: 1.3685 - val_loss: 0.3522 - val_accuracy: 0.8727 - val_myMetric: 1.2582\n",
      "Epoch 3/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3827 - accuracy: 0.8604 - myMetric: 1.3053 - val_loss: 0.3417 - val_accuracy: 0.8780 - val_myMetric: 1.2104\n",
      "Epoch 4/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3589 - accuracy: 0.8696 - myMetric: 1.2733 - val_loss: 0.3349 - val_accuracy: 0.8830 - val_myMetric: 1.2162\n",
      "Epoch 5/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3384 - accuracy: 0.8758 - myMetric: 1.2505 - val_loss: 0.3074 - val_accuracy: 0.8933 - val_myMetric: 1.1975\n",
      "Epoch 6/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3210 - accuracy: 0.8820 - myMetric: 1.2275 - val_loss: 0.3287 - val_accuracy: 0.8890 - val_myMetric: 1.1876\n",
      "Epoch 7/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3112 - accuracy: 0.8847 - myMetric: 1.2135 - val_loss: 0.2946 - val_accuracy: 0.8984 - val_myMetric: 1.2077\n",
      "Epoch 8/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2984 - accuracy: 0.8895 - myMetric: 1.2035 - val_loss: 0.2865 - val_accuracy: 0.9030 - val_myMetric: 1.1586\n",
      "Epoch 9/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2900 - accuracy: 0.8932 - myMetric: 1.1928 - val_loss: 0.2939 - val_accuracy: 0.9054 - val_myMetric: 1.1539\n",
      "Epoch 10/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2752 - accuracy: 0.8977 - myMetric: 1.1784 - val_loss: 0.2615 - val_accuracy: 0.9097 - val_myMetric: 1.1142\n",
      "Epoch 11/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2704 - accuracy: 0.8998 - myMetric: 1.1690 - val_loss: 0.2622 - val_accuracy: 0.9142 - val_myMetric: 1.1148\n",
      "Epoch 12/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2594 - accuracy: 0.9031 - myMetric: 1.1627 - val_loss: 0.2681 - val_accuracy: 0.9103 - val_myMetric: 1.1250\n",
      "Epoch 13/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2499 - accuracy: 0.9079 - myMetric: 1.1492 - val_loss: 0.2377 - val_accuracy: 0.9203 - val_myMetric: 1.1077\n",
      "Epoch 14/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2437 - accuracy: 0.9087 - myMetric: 1.1429 - val_loss: 0.2627 - val_accuracy: 0.9140 - val_myMetric: 1.1040\n",
      "Epoch 15/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2379 - accuracy: 0.9097 - myMetric: 1.1357 - val_loss: 0.2447 - val_accuracy: 0.9209 - val_myMetric: 1.1040\n",
      "Epoch 16/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2280 - accuracy: 0.9153 - myMetric: 1.1269 - val_loss: 0.2474 - val_accuracy: 0.9242 - val_myMetric: 1.0918\n",
      "Epoch 17/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2247 - accuracy: 0.9141 - myMetric: 1.1230 - val_loss: 0.2286 - val_accuracy: 0.9231 - val_myMetric: 1.0860\n",
      "Epoch 18/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2205 - accuracy: 0.9165 - myMetric: 1.1176 - val_loss: 0.2130 - val_accuracy: 0.9269 - val_myMetric: 1.0842\n",
      "Epoch 19/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2129 - accuracy: 0.9192 - myMetric: 1.1116 - val_loss: 0.2517 - val_accuracy: 0.9297 - val_myMetric: 1.0712\n",
      "Epoch 20/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2084 - accuracy: 0.9221 - myMetric: 1.1049 - val_loss: 0.2187 - val_accuracy: 0.9335 - val_myMetric: 1.0674\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.5383 - accuracy: 0.8834 - myMetric: 1.0991\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 40\u001b[0m\n\u001b[0;32m     36\u001b[0m history2_1 \u001b[38;5;241m=\u001b[39m model2_1\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m     37\u001b[0m                     validation_data\u001b[38;5;241m=\u001b[39m(X_valid, y_valid))\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m#Step 5 - Check for overfitting and retest if needed (STOP HERE BASED ON ASSIGNMENT REQS)\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m mse_test, rmse_test \u001b[38;5;241m=\u001b[39m model2_1\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m#Step 6 - Visualize the data\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "#Step 1 - Import the data\n",
    "#Also split the data into training and test sets, also hold out the last 5000 images from training/testing\n",
    "fashionMnist = tf.keras.datasets.fashion_mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashionMnist\n",
    "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
    "X_valid, y_valid = X_train_full[:-5000], y_train_full[:-5000]\n",
    "\n",
    "#Step 2 - Create the neural net structure\n",
    "#get_layer() and get_weights() to see layers and weight\n",
    "tf.random.set_seed(42)\n",
    "model2_1 = tf.keras.Sequential()\n",
    "model2_1.add(tf.keras.layers.InputLayer(input_shape=[28, 28]))\n",
    "model2_1.add(tf.keras.layers.Flatten())\n",
    "model2_1.add(tf.keras.layers.Dense(300, activation=\"relu\"))\n",
    "#batch normalization layer moved and moved another hidden layer between batch and dropout\n",
    "model2_1.add(tf.keras.layers.BatchNormalization())\n",
    "model2_1.add(tf.keras.layers.Dense(250, activation=\"relu\"))\n",
    "model2_1.add(tf.keras.layers.Dense(200, activation=\"relu\"))\n",
    "#dropout layer moved\n",
    "model2_1.add(tf.keras.layers.Dropout(.2))\n",
    "#more hidden layers\n",
    "model2_1.add(tf.keras.layers.Dense(150, activation=\"relu\"))\n",
    "#added this layer\n",
    "model2_1.add(myLayer)\n",
    "model2_1.add(tf.keras.layers.Dense(50, activation=\"relu\"))\n",
    "model2_1.add(myLayer)\n",
    "model2_1.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model2_1.summary()\n",
    "\n",
    "#Step 3 - Compile the model\n",
    "#edited learning rate to .05 instead of .01\n",
    "model2_1.compile(loss=\"sparse_categorical_crossentropy\", optimizer = tf.keras.optimizers.SGD(learning_rate=0.01), metrics=[myMetric])\n",
    "\n",
    "#Step 4 - Train and evaluate model, epoch was 30 shortened to 20 for speed\n",
    "history2_1 = model2_1.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "\n",
    "#Step 5 - Check for overfitting and retest if needed (STOP HERE BASED ON ASSIGNMENT REQS)\n",
    "mse_test, rmse_test = model2_1.evaluate(X_test, y_test)\n",
    "\n",
    "#Step 6 - Visualize the data\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history2_1.history).plot(\n",
    "    figsize=(8, 5), xlim=[0, 29], ylim=[0, 1], grid=True, xlabel=\"Epoch\",\n",
    "    style=[\"r--\", \"r--.\", \"b-\", \"b-*\"])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
